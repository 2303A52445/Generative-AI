{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303A52445/Generative-AI/blob/main/GAI_ass_7_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the training set\n",
        "_, train_accuracy = model.evaluate(X_train, y_train, verbose=0)\n",
        "print(f'Training Accuracy: {train_accuracy * 100:.2f}%')\n",
        "\n",
        "# Evaluate the model on the testing set\n",
        "_, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f'Testing Accuracy: {test_accuracy * 100:.2f}%')\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_prob = model.predict(X_test)\n",
        "y_pred = (y_pred_prob > 0.5).astype(int) #convert probabilities to binary values\n",
        "\n",
        "# Calculate confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print('Confusion Matrix:')\n",
        "print(conf_matrix)\n",
        "\n",
        "# Calculate recall, precision, and F1-score\n",
        "recall = recall_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'F1-Score: {f1:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7xxUvlmoeVv",
        "outputId": "cd663a5e-9133-4f6b-df7f-9cf8b6304949"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 90.88%\n",
            "Testing Accuracy: 70.78%\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Confusion Matrix:\n",
            "[[75 24]\n",
            " [21 34]]\n",
            "Recall: 0.6182\n",
            "Precision: 0.5862\n",
            "F1-Score: 0.6018\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import necessary libraries\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 2: Load the dataset (replace with the actual dataset path)\n",
        "# Make sure to replace 'path_to_your_dataset.csv' with the actual path to your dataset.\n",
        "dataset = pd.read_csv('/content/diabetes (1).csv')  # Load dataset\n",
        "\n",
        "# Step 3: Preprocess the data\n",
        "# Assuming 'Outcome' is the target variable (1 for diabetic, 0 for non-diabetic)\n",
        "X = dataset.drop(columns=['Outcome'])  # Features\n",
        "y = dataset['Outcome']  # Target variable\n",
        "\n",
        "# Normalize the features using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Split the data into training and testing sets (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 4: Build the ANN model\n",
        "model = Sequential()\n",
        "\n",
        "# Input layer and Hidden Layer 1 (10 neurons, tanh activation)\n",
        "model.add(Dense(10, input_dim=X_train.shape[1], activation='tanh'))\n",
        "\n",
        "# Hidden Layer 2 (15 neurons, tanh activation)\n",
        "model.add(Dense(15, activation='tanh'))\n",
        "\n",
        "# Hidden Layer 3 (20 neurons, tanh activation)\n",
        "model.add(Dense(20, activation='tanh'))\n",
        "\n",
        "# Hidden Layer 4 (10 neurons, tanh activation)\n",
        "model.add(Dense(10, activation='tanh'))\n",
        "\n",
        "# Hidden Layer 5 (5 neurons, tanh activation)\n",
        "model.add(Dense(5, activation='tanh'))\n",
        "\n",
        "# Output Layer (1 neuron for binary classification)\n",
        "model.add(Dense(1, activation='sigmoid'))  # Sigmoid activation for binary classification\n",
        "\n",
        "# Step 5: Compile the model with Adam optimizer, accuracy metric, and binary crossentropy loss function\n",
        "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 6: Train the model (epochs=250, batch_size=32)\n",
        "history = model.fit(X_train, y_train, epochs=250, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Step 7: Evaluate the model on the test data\n",
        "train_loss, train_accuracy = model.evaluate(X_train, y_train)\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "\n",
        "# Output training and testing accuracy\n",
        "print(f'Training Accuracy: {train_accuracy}')\n",
        "print(f'Testing Accuracy: {test_accuracy}')\n",
        "\n",
        "# Step 8: Save the model to a .h5 file\n",
        "model.save('diabetes_diagnosis_model.h5')\n",
        "\n",
        "# Step 9: (Evaluation) Calculate confusion matrix and classification metrics\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = (y_pred > 0.5).astype(int)  # Convert probabilities to binary class predictions\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Precision, Recall, and F1-Score\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1-Score: {f1}')\n",
        "\n",
        "# Plotting confusion matrix\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Non-Diabetic', 'Diabetic'], yticklabels=['Non-Diabetic', 'Diabetic'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "# Step 10: (Deployment) Load the saved model for future predictions\n",
        "from keras.models import load_model\n",
        "\n",
        "# Load the saved model\n",
        "loaded_model = load_model('diabetes_diagnosis_model.h5')\n",
        "\n",
        "# Example prediction on new data\n",
        "# Replace these placeholder values with actual values for a new patient\n",
        "# The number of values here should match the number of features (e.g., 10 values for 10 features)\n",
        "# Example prediction on new data\n",
        "# Replace these placeholder values with actual values for a new patient\n",
        "# The number of values here should match the number of features (e.g., 8 values for 8 features)\n",
        "\n",
        "new_data = [[5.1, 3.5, 1.4, 0.2, 6.0, 3.0, 4.5, 1.5]]  # Replace with actual new feature values (8 features)\n",
        "\n",
        "# Scale the new data using the same scaler used during training\n",
        "new_data = scaler.transform(new_data)\n",
        "\n",
        "# Make the prediction\n",
        "predicted_outcome = loaded_model.predict(new_data)\n",
        "\n",
        "# Convert the prediction to 0 or 1 (Diabetic or Non-Diabetic)\n",
        "predicted_class = (predicted_outcome > 0.5).astype(int)\n",
        "\n",
        "# Print the predicted class (0: Non-Diabetic, 1: Diabetic)\n",
        "print(f'Predicted Class (0: Non-Diabetic, 1: Diabetic): {predicted_class[0][0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AKT7_uLMnX0T",
        "outputId": "dfd68533-1ffd-4bdb-e9df-bff7fb768a74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.5466 - loss: 0.6948 - val_accuracy: 0.6753 - val_loss: 0.6125\n",
            "Epoch 2/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7157 - loss: 0.5696 - val_accuracy: 0.7273 - val_loss: 0.5419\n",
            "Epoch 3/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7602 - loss: 0.5137 - val_accuracy: 0.7662 - val_loss: 0.5174\n",
            "Epoch 4/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7612 - loss: 0.4899 - val_accuracy: 0.7987 - val_loss: 0.5076\n",
            "Epoch 5/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7791 - loss: 0.5013 - val_accuracy: 0.7857 - val_loss: 0.5054\n",
            "Epoch 6/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7657 - loss: 0.5016 - val_accuracy: 0.7662 - val_loss: 0.5103\n",
            "Epoch 7/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7850 - loss: 0.4709 - val_accuracy: 0.7338 - val_loss: 0.5135\n",
            "Epoch 8/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7818 - loss: 0.4642 - val_accuracy: 0.7338 - val_loss: 0.5299\n",
            "Epoch 9/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7401 - loss: 0.4921 - val_accuracy: 0.7338 - val_loss: 0.5155\n",
            "Epoch 10/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7571 - loss: 0.4807 - val_accuracy: 0.7597 - val_loss: 0.5157\n",
            "Epoch 11/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7695 - loss: 0.4689 - val_accuracy: 0.7597 - val_loss: 0.5169\n",
            "Epoch 12/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7632 - loss: 0.4729 - val_accuracy: 0.7468 - val_loss: 0.5195\n",
            "Epoch 13/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7875 - loss: 0.4581 - val_accuracy: 0.7468 - val_loss: 0.5221\n",
            "Epoch 14/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7636 - loss: 0.4577 - val_accuracy: 0.7532 - val_loss: 0.5196\n",
            "Epoch 15/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7714 - loss: 0.4839 - val_accuracy: 0.7338 - val_loss: 0.5280\n",
            "Epoch 16/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7728 - loss: 0.4786 - val_accuracy: 0.7273 - val_loss: 0.5366\n",
            "Epoch 17/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7685 - loss: 0.4623 - val_accuracy: 0.7403 - val_loss: 0.5322\n",
            "Epoch 18/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7844 - loss: 0.4649 - val_accuracy: 0.7338 - val_loss: 0.5309\n",
            "Epoch 19/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7831 - loss: 0.4524 - val_accuracy: 0.7597 - val_loss: 0.5284\n",
            "Epoch 20/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7880 - loss: 0.4460 - val_accuracy: 0.7403 - val_loss: 0.5346\n",
            "Epoch 21/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7769 - loss: 0.4695 - val_accuracy: 0.7532 - val_loss: 0.5305\n",
            "Epoch 22/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7732 - loss: 0.4596 - val_accuracy: 0.7468 - val_loss: 0.5299\n",
            "Epoch 23/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7661 - loss: 0.4462 - val_accuracy: 0.7597 - val_loss: 0.5280\n",
            "Epoch 24/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8243 - loss: 0.4092 - val_accuracy: 0.7468 - val_loss: 0.5389\n",
            "Epoch 25/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7932 - loss: 0.4472 - val_accuracy: 0.7597 - val_loss: 0.5309\n",
            "Epoch 26/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7752 - loss: 0.4671 - val_accuracy: 0.7662 - val_loss: 0.5354\n",
            "Epoch 27/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7958 - loss: 0.4442 - val_accuracy: 0.7532 - val_loss: 0.5360\n",
            "Epoch 28/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7815 - loss: 0.4528 - val_accuracy: 0.7662 - val_loss: 0.5345\n",
            "Epoch 29/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8118 - loss: 0.4115 - val_accuracy: 0.7597 - val_loss: 0.5312\n",
            "Epoch 30/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8192 - loss: 0.4245 - val_accuracy: 0.7662 - val_loss: 0.5341\n",
            "Epoch 31/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8131 - loss: 0.4294 - val_accuracy: 0.7662 - val_loss: 0.5310\n",
            "Epoch 32/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8022 - loss: 0.4558 - val_accuracy: 0.7338 - val_loss: 0.5388\n",
            "Epoch 33/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8154 - loss: 0.4122 - val_accuracy: 0.7597 - val_loss: 0.5313\n",
            "Epoch 34/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8340 - loss: 0.4033 - val_accuracy: 0.7468 - val_loss: 0.5337\n",
            "Epoch 35/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7825 - loss: 0.4570 - val_accuracy: 0.7532 - val_loss: 0.5310\n",
            "Epoch 36/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7762 - loss: 0.4611 - val_accuracy: 0.7662 - val_loss: 0.5300\n",
            "Epoch 37/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8016 - loss: 0.4354 - val_accuracy: 0.7532 - val_loss: 0.5403\n",
            "Epoch 38/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8050 - loss: 0.4334 - val_accuracy: 0.7597 - val_loss: 0.5381\n",
            "Epoch 39/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8143 - loss: 0.4238 - val_accuracy: 0.7597 - val_loss: 0.5368\n",
            "Epoch 40/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8142 - loss: 0.4218 - val_accuracy: 0.7338 - val_loss: 0.5408\n",
            "Epoch 41/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8142 - loss: 0.4307 - val_accuracy: 0.7403 - val_loss: 0.5481\n",
            "Epoch 42/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8172 - loss: 0.4187 - val_accuracy: 0.7792 - val_loss: 0.5419\n",
            "Epoch 43/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8068 - loss: 0.4283 - val_accuracy: 0.7532 - val_loss: 0.5453\n",
            "Epoch 44/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7888 - loss: 0.4544 - val_accuracy: 0.7662 - val_loss: 0.5358\n",
            "Epoch 45/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7968 - loss: 0.4253 - val_accuracy: 0.7468 - val_loss: 0.5359\n",
            "Epoch 46/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7767 - loss: 0.4629 - val_accuracy: 0.7532 - val_loss: 0.5358\n",
            "Epoch 47/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8087 - loss: 0.4163 - val_accuracy: 0.7468 - val_loss: 0.5366\n",
            "Epoch 48/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8095 - loss: 0.4240 - val_accuracy: 0.7597 - val_loss: 0.5357\n",
            "Epoch 49/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8013 - loss: 0.4418 - val_accuracy: 0.7208 - val_loss: 0.5391\n",
            "Epoch 50/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7787 - loss: 0.4676 - val_accuracy: 0.7532 - val_loss: 0.5402\n",
            "Epoch 51/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8113 - loss: 0.4313 - val_accuracy: 0.7338 - val_loss: 0.5389\n",
            "Epoch 52/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8086 - loss: 0.4238 - val_accuracy: 0.7597 - val_loss: 0.5257\n",
            "Epoch 53/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7878 - loss: 0.4483 - val_accuracy: 0.7662 - val_loss: 0.5376\n",
            "Epoch 54/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8104 - loss: 0.4341 - val_accuracy: 0.7403 - val_loss: 0.5290\n",
            "Epoch 55/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8012 - loss: 0.4400 - val_accuracy: 0.7597 - val_loss: 0.5381\n",
            "Epoch 56/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8176 - loss: 0.3981 - val_accuracy: 0.7338 - val_loss: 0.5457\n",
            "Epoch 57/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8264 - loss: 0.4133 - val_accuracy: 0.7597 - val_loss: 0.5372\n",
            "Epoch 58/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8283 - loss: 0.4034 - val_accuracy: 0.7468 - val_loss: 0.5376\n",
            "Epoch 59/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8126 - loss: 0.3986 - val_accuracy: 0.7403 - val_loss: 0.5447\n",
            "Epoch 60/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8150 - loss: 0.4115 - val_accuracy: 0.7597 - val_loss: 0.5380\n",
            "Epoch 61/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8257 - loss: 0.4093 - val_accuracy: 0.7532 - val_loss: 0.5345\n",
            "Epoch 62/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8222 - loss: 0.3983 - val_accuracy: 0.7597 - val_loss: 0.5394\n",
            "Epoch 63/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8173 - loss: 0.4138 - val_accuracy: 0.7403 - val_loss: 0.5435\n",
            "Epoch 64/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8158 - loss: 0.4059 - val_accuracy: 0.7727 - val_loss: 0.5261\n",
            "Epoch 65/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8382 - loss: 0.3939 - val_accuracy: 0.7662 - val_loss: 0.5290\n",
            "Epoch 66/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8445 - loss: 0.3765 - val_accuracy: 0.7662 - val_loss: 0.5265\n",
            "Epoch 67/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8113 - loss: 0.4161 - val_accuracy: 0.7338 - val_loss: 0.5361\n",
            "Epoch 68/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8158 - loss: 0.4145 - val_accuracy: 0.7857 - val_loss: 0.5320\n",
            "Epoch 69/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8240 - loss: 0.4062 - val_accuracy: 0.7597 - val_loss: 0.5323\n",
            "Epoch 70/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8167 - loss: 0.4001 - val_accuracy: 0.7727 - val_loss: 0.5389\n",
            "Epoch 71/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8130 - loss: 0.4209 - val_accuracy: 0.7662 - val_loss: 0.5360\n",
            "Epoch 72/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8401 - loss: 0.4044 - val_accuracy: 0.7532 - val_loss: 0.5456\n",
            "Epoch 73/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8331 - loss: 0.3939 - val_accuracy: 0.7662 - val_loss: 0.5451\n",
            "Epoch 74/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8058 - loss: 0.4061 - val_accuracy: 0.7597 - val_loss: 0.5369\n",
            "Epoch 75/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8089 - loss: 0.4036 - val_accuracy: 0.7727 - val_loss: 0.5366\n",
            "Epoch 76/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8363 - loss: 0.3855 - val_accuracy: 0.7727 - val_loss: 0.5498\n",
            "Epoch 77/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8194 - loss: 0.4127 - val_accuracy: 0.7468 - val_loss: 0.5423\n",
            "Epoch 78/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8046 - loss: 0.4233 - val_accuracy: 0.7532 - val_loss: 0.5439\n",
            "Epoch 79/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8418 - loss: 0.3592 - val_accuracy: 0.7468 - val_loss: 0.5449\n",
            "Epoch 80/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8156 - loss: 0.4092 - val_accuracy: 0.7468 - val_loss: 0.5469\n",
            "Epoch 81/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8270 - loss: 0.4019 - val_accuracy: 0.7532 - val_loss: 0.5556\n",
            "Epoch 82/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8508 - loss: 0.3583 - val_accuracy: 0.7532 - val_loss: 0.5507\n",
            "Epoch 83/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7937 - loss: 0.4260 - val_accuracy: 0.7468 - val_loss: 0.5524\n",
            "Epoch 84/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8258 - loss: 0.3880 - val_accuracy: 0.7468 - val_loss: 0.5530\n",
            "Epoch 85/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8311 - loss: 0.3952 - val_accuracy: 0.7597 - val_loss: 0.5565\n",
            "Epoch 86/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8041 - loss: 0.4266 - val_accuracy: 0.7532 - val_loss: 0.5500\n",
            "Epoch 87/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8184 - loss: 0.3969 - val_accuracy: 0.7468 - val_loss: 0.5557\n",
            "Epoch 88/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8164 - loss: 0.4202 - val_accuracy: 0.7597 - val_loss: 0.5489\n",
            "Epoch 89/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8329 - loss: 0.4044 - val_accuracy: 0.7597 - val_loss: 0.5637\n",
            "Epoch 90/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8411 - loss: 0.3722 - val_accuracy: 0.7468 - val_loss: 0.5498\n",
            "Epoch 91/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8347 - loss: 0.3853 - val_accuracy: 0.7532 - val_loss: 0.5579\n",
            "Epoch 92/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8242 - loss: 0.3969 - val_accuracy: 0.7468 - val_loss: 0.5622\n",
            "Epoch 93/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8221 - loss: 0.4085 - val_accuracy: 0.7468 - val_loss: 0.5491\n",
            "Epoch 94/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8511 - loss: 0.3647 - val_accuracy: 0.7662 - val_loss: 0.5503\n",
            "Epoch 95/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8226 - loss: 0.4042 - val_accuracy: 0.7468 - val_loss: 0.5599\n",
            "Epoch 96/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8466 - loss: 0.3695 - val_accuracy: 0.7468 - val_loss: 0.5617\n",
            "Epoch 97/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8405 - loss: 0.3751 - val_accuracy: 0.7403 - val_loss: 0.5673\n",
            "Epoch 98/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8193 - loss: 0.4224 - val_accuracy: 0.7403 - val_loss: 0.5576\n",
            "Epoch 99/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8456 - loss: 0.3807 - val_accuracy: 0.7532 - val_loss: 0.5533\n",
            "Epoch 100/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8296 - loss: 0.3789 - val_accuracy: 0.7468 - val_loss: 0.5655\n",
            "Epoch 101/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8340 - loss: 0.4010 - val_accuracy: 0.7403 - val_loss: 0.5619\n",
            "Epoch 102/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8032 - loss: 0.4093 - val_accuracy: 0.7468 - val_loss: 0.5575\n",
            "Epoch 103/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8478 - loss: 0.3678 - val_accuracy: 0.7273 - val_loss: 0.5659\n",
            "Epoch 104/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8246 - loss: 0.3807 - val_accuracy: 0.7273 - val_loss: 0.5591\n",
            "Epoch 105/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8294 - loss: 0.4039 - val_accuracy: 0.7403 - val_loss: 0.5666\n",
            "Epoch 106/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8300 - loss: 0.3780 - val_accuracy: 0.7208 - val_loss: 0.5729\n",
            "Epoch 107/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8134 - loss: 0.4197 - val_accuracy: 0.7403 - val_loss: 0.5642\n",
            "Epoch 108/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8451 - loss: 0.3573 - val_accuracy: 0.7468 - val_loss: 0.5701\n",
            "Epoch 109/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8363 - loss: 0.3719 - val_accuracy: 0.7532 - val_loss: 0.5605\n",
            "Epoch 110/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8346 - loss: 0.3690 - val_accuracy: 0.7143 - val_loss: 0.5705\n",
            "Epoch 111/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8321 - loss: 0.3622 - val_accuracy: 0.7403 - val_loss: 0.5697\n",
            "Epoch 112/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8170 - loss: 0.3904 - val_accuracy: 0.7273 - val_loss: 0.5718\n",
            "Epoch 113/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8179 - loss: 0.3797 - val_accuracy: 0.7143 - val_loss: 0.5740\n",
            "Epoch 114/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8217 - loss: 0.3879 - val_accuracy: 0.7338 - val_loss: 0.5737\n",
            "Epoch 115/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8354 - loss: 0.3512 - val_accuracy: 0.7403 - val_loss: 0.5683\n",
            "Epoch 116/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8604 - loss: 0.3628 - val_accuracy: 0.7208 - val_loss: 0.5775\n",
            "Epoch 117/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8288 - loss: 0.3582 - val_accuracy: 0.7208 - val_loss: 0.5725\n",
            "Epoch 118/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8151 - loss: 0.3809 - val_accuracy: 0.7338 - val_loss: 0.5728\n",
            "Epoch 119/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8377 - loss: 0.3760 - val_accuracy: 0.7208 - val_loss: 0.5807\n",
            "Epoch 120/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8256 - loss: 0.3549 - val_accuracy: 0.7468 - val_loss: 0.5740\n",
            "Epoch 121/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8393 - loss: 0.3712 - val_accuracy: 0.7338 - val_loss: 0.5731\n",
            "Epoch 122/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8260 - loss: 0.3972 - val_accuracy: 0.7208 - val_loss: 0.5780\n",
            "Epoch 123/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8566 - loss: 0.3471 - val_accuracy: 0.7273 - val_loss: 0.5799\n",
            "Epoch 124/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8540 - loss: 0.3471 - val_accuracy: 0.7143 - val_loss: 0.5886\n",
            "Epoch 125/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8429 - loss: 0.3369 - val_accuracy: 0.7273 - val_loss: 0.5861\n",
            "Epoch 126/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8397 - loss: 0.3554 - val_accuracy: 0.7273 - val_loss: 0.5782\n",
            "Epoch 127/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8424 - loss: 0.3613 - val_accuracy: 0.7208 - val_loss: 0.5915\n",
            "Epoch 128/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8460 - loss: 0.3474 - val_accuracy: 0.7208 - val_loss: 0.5962\n",
            "Epoch 129/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8484 - loss: 0.3649 - val_accuracy: 0.7273 - val_loss: 0.5880\n",
            "Epoch 130/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8457 - loss: 0.3638 - val_accuracy: 0.7338 - val_loss: 0.5929\n",
            "Epoch 131/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8438 - loss: 0.3430 - val_accuracy: 0.7403 - val_loss: 0.5762\n",
            "Epoch 132/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8599 - loss: 0.3461 - val_accuracy: 0.7403 - val_loss: 0.5925\n",
            "Epoch 133/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8518 - loss: 0.3412 - val_accuracy: 0.7403 - val_loss: 0.5787\n",
            "Epoch 134/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8374 - loss: 0.3500 - val_accuracy: 0.7273 - val_loss: 0.5973\n",
            "Epoch 135/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8628 - loss: 0.3366 - val_accuracy: 0.7338 - val_loss: 0.5957\n",
            "Epoch 136/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8265 - loss: 0.3620 - val_accuracy: 0.7338 - val_loss: 0.5913\n",
            "Epoch 137/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8463 - loss: 0.3375 - val_accuracy: 0.7273 - val_loss: 0.5965\n",
            "Epoch 138/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8480 - loss: 0.3489 - val_accuracy: 0.7208 - val_loss: 0.6088\n",
            "Epoch 139/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8407 - loss: 0.3447 - val_accuracy: 0.7273 - val_loss: 0.6043\n",
            "Epoch 140/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8528 - loss: 0.3288 - val_accuracy: 0.7338 - val_loss: 0.6021\n",
            "Epoch 141/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8507 - loss: 0.3345 - val_accuracy: 0.7338 - val_loss: 0.6037\n",
            "Epoch 142/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8389 - loss: 0.3502 - val_accuracy: 0.7208 - val_loss: 0.6185\n",
            "Epoch 143/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8706 - loss: 0.3143 - val_accuracy: 0.7273 - val_loss: 0.6132\n",
            "Epoch 144/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8470 - loss: 0.3299 - val_accuracy: 0.7208 - val_loss: 0.6151\n",
            "Epoch 145/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8579 - loss: 0.3106 - val_accuracy: 0.7208 - val_loss: 0.6133\n",
            "Epoch 146/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8430 - loss: 0.3319 - val_accuracy: 0.7208 - val_loss: 0.6140\n",
            "Epoch 147/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8463 - loss: 0.3394 - val_accuracy: 0.7208 - val_loss: 0.6074\n",
            "Epoch 148/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8593 - loss: 0.3378 - val_accuracy: 0.7208 - val_loss: 0.6224\n",
            "Epoch 149/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8385 - loss: 0.3512 - val_accuracy: 0.7208 - val_loss: 0.6163\n",
            "Epoch 150/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8460 - loss: 0.3490 - val_accuracy: 0.7208 - val_loss: 0.6340\n",
            "Epoch 151/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8556 - loss: 0.3094 - val_accuracy: 0.7208 - val_loss: 0.6207\n",
            "Epoch 152/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8434 - loss: 0.3586 - val_accuracy: 0.7338 - val_loss: 0.6301\n",
            "Epoch 153/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8624 - loss: 0.3235 - val_accuracy: 0.7273 - val_loss: 0.6277\n",
            "Epoch 154/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8441 - loss: 0.3364 - val_accuracy: 0.7273 - val_loss: 0.6270\n",
            "Epoch 155/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8589 - loss: 0.3201 - val_accuracy: 0.7208 - val_loss: 0.6288\n",
            "Epoch 156/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8384 - loss: 0.3188 - val_accuracy: 0.7338 - val_loss: 0.6328\n",
            "Epoch 157/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8467 - loss: 0.3406 - val_accuracy: 0.7273 - val_loss: 0.6292\n",
            "Epoch 158/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8432 - loss: 0.3370 - val_accuracy: 0.7338 - val_loss: 0.6263\n",
            "Epoch 159/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8181 - loss: 0.3790 - val_accuracy: 0.7273 - val_loss: 0.6295\n",
            "Epoch 160/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8542 - loss: 0.3389 - val_accuracy: 0.7208 - val_loss: 0.6293\n",
            "Epoch 161/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8685 - loss: 0.3041 - val_accuracy: 0.7338 - val_loss: 0.6413\n",
            "Epoch 162/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8599 - loss: 0.3241 - val_accuracy: 0.7208 - val_loss: 0.6392\n",
            "Epoch 163/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8340 - loss: 0.3680 - val_accuracy: 0.7273 - val_loss: 0.6351\n",
            "Epoch 164/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8548 - loss: 0.3312 - val_accuracy: 0.7273 - val_loss: 0.6437\n",
            "Epoch 165/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8640 - loss: 0.3131 - val_accuracy: 0.7338 - val_loss: 0.6482\n",
            "Epoch 166/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8434 - loss: 0.3353 - val_accuracy: 0.7338 - val_loss: 0.6348\n",
            "Epoch 167/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8744 - loss: 0.2998 - val_accuracy: 0.7403 - val_loss: 0.6249\n",
            "Epoch 168/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8571 - loss: 0.3294 - val_accuracy: 0.7338 - val_loss: 0.6393\n",
            "Epoch 169/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8510 - loss: 0.3330 - val_accuracy: 0.7338 - val_loss: 0.6349\n",
            "Epoch 170/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8487 - loss: 0.3161 - val_accuracy: 0.7338 - val_loss: 0.6476\n",
            "Epoch 171/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8610 - loss: 0.3168 - val_accuracy: 0.7338 - val_loss: 0.6451\n",
            "Epoch 172/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8738 - loss: 0.3033 - val_accuracy: 0.7338 - val_loss: 0.6433\n",
            "Epoch 173/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8666 - loss: 0.3111 - val_accuracy: 0.7338 - val_loss: 0.6454\n",
            "Epoch 174/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8515 - loss: 0.3120 - val_accuracy: 0.7338 - val_loss: 0.6373\n",
            "Epoch 175/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8464 - loss: 0.3078 - val_accuracy: 0.7273 - val_loss: 0.6547\n",
            "Epoch 176/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8729 - loss: 0.2990 - val_accuracy: 0.7338 - val_loss: 0.6525\n",
            "Epoch 177/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8508 - loss: 0.3189 - val_accuracy: 0.7403 - val_loss: 0.6571\n",
            "Epoch 178/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8674 - loss: 0.2814 - val_accuracy: 0.7338 - val_loss: 0.6504\n",
            "Epoch 179/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8618 - loss: 0.3095 - val_accuracy: 0.7273 - val_loss: 0.6486\n",
            "Epoch 180/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8601 - loss: 0.3078 - val_accuracy: 0.7403 - val_loss: 0.6482\n",
            "Epoch 181/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8617 - loss: 0.3233 - val_accuracy: 0.7338 - val_loss: 0.6579\n",
            "Epoch 182/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8597 - loss: 0.3089 - val_accuracy: 0.7338 - val_loss: 0.6530\n",
            "Epoch 183/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8320 - loss: 0.3377 - val_accuracy: 0.7403 - val_loss: 0.6381\n",
            "Epoch 184/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8453 - loss: 0.3144 - val_accuracy: 0.7403 - val_loss: 0.6566\n",
            "Epoch 185/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8688 - loss: 0.3009 - val_accuracy: 0.7208 - val_loss: 0.6499\n",
            "Epoch 186/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8756 - loss: 0.2808 - val_accuracy: 0.7403 - val_loss: 0.6532\n",
            "Epoch 187/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8533 - loss: 0.3145 - val_accuracy: 0.7403 - val_loss: 0.6633\n",
            "Epoch 188/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8613 - loss: 0.3144 - val_accuracy: 0.7208 - val_loss: 0.6596\n",
            "Epoch 189/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8592 - loss: 0.2865 - val_accuracy: 0.7338 - val_loss: 0.6490\n",
            "Epoch 190/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8607 - loss: 0.2737 - val_accuracy: 0.7338 - val_loss: 0.6606\n",
            "Epoch 191/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8664 - loss: 0.2940 - val_accuracy: 0.7403 - val_loss: 0.6592\n",
            "Epoch 192/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8667 - loss: 0.2825 - val_accuracy: 0.7403 - val_loss: 0.6608\n",
            "Epoch 193/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8465 - loss: 0.3094 - val_accuracy: 0.7403 - val_loss: 0.6615\n",
            "Epoch 194/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8628 - loss: 0.2676 - val_accuracy: 0.7403 - val_loss: 0.6666\n",
            "Epoch 195/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8697 - loss: 0.2841 - val_accuracy: 0.7338 - val_loss: 0.6662\n",
            "Epoch 196/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8648 - loss: 0.2783 - val_accuracy: 0.7403 - val_loss: 0.6438\n",
            "Epoch 197/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8644 - loss: 0.2732 - val_accuracy: 0.7403 - val_loss: 0.6572\n",
            "Epoch 198/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8780 - loss: 0.2628 - val_accuracy: 0.7338 - val_loss: 0.6652\n",
            "Epoch 199/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8798 - loss: 0.2874 - val_accuracy: 0.7208 - val_loss: 0.6661\n",
            "Epoch 200/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8697 - loss: 0.2842 - val_accuracy: 0.7338 - val_loss: 0.6648\n",
            "Epoch 201/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8637 - loss: 0.2770 - val_accuracy: 0.7403 - val_loss: 0.6688\n",
            "Epoch 202/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8732 - loss: 0.2718 - val_accuracy: 0.7403 - val_loss: 0.6662\n",
            "Epoch 203/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8660 - loss: 0.3075 - val_accuracy: 0.7338 - val_loss: 0.6742\n",
            "Epoch 204/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8597 - loss: 0.2767 - val_accuracy: 0.7403 - val_loss: 0.6735\n",
            "Epoch 205/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8522 - loss: 0.2860 - val_accuracy: 0.7403 - val_loss: 0.6630\n",
            "Epoch 206/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8844 - loss: 0.2841 - val_accuracy: 0.7403 - val_loss: 0.6884\n",
            "Epoch 207/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8744 - loss: 0.2858 - val_accuracy: 0.7403 - val_loss: 0.6834\n",
            "Epoch 208/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8682 - loss: 0.2580 - val_accuracy: 0.7403 - val_loss: 0.6830\n",
            "Epoch 209/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8623 - loss: 0.2819 - val_accuracy: 0.7338 - val_loss: 0.6740\n",
            "Epoch 210/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8866 - loss: 0.2486 - val_accuracy: 0.7078 - val_loss: 0.6905\n",
            "Epoch 211/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8729 - loss: 0.2598 - val_accuracy: 0.7338 - val_loss: 0.7005\n",
            "Epoch 212/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8806 - loss: 0.2621 - val_accuracy: 0.7468 - val_loss: 0.6874\n",
            "Epoch 213/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8897 - loss: 0.2577 - val_accuracy: 0.7338 - val_loss: 0.6954\n",
            "Epoch 214/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8753 - loss: 0.2933 - val_accuracy: 0.7403 - val_loss: 0.6905\n",
            "Epoch 215/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8658 - loss: 0.3056 - val_accuracy: 0.7403 - val_loss: 0.6922\n",
            "Epoch 216/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8835 - loss: 0.2591 - val_accuracy: 0.7273 - val_loss: 0.7032\n",
            "Epoch 217/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8755 - loss: 0.2723 - val_accuracy: 0.7338 - val_loss: 0.6996\n",
            "Epoch 218/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8732 - loss: 0.2824 - val_accuracy: 0.7338 - val_loss: 0.7016\n",
            "Epoch 219/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8991 - loss: 0.2564 - val_accuracy: 0.7403 - val_loss: 0.6968\n",
            "Epoch 220/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8803 - loss: 0.2530 - val_accuracy: 0.7273 - val_loss: 0.6932\n",
            "Epoch 221/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8777 - loss: 0.2514 - val_accuracy: 0.7273 - val_loss: 0.6962\n",
            "Epoch 222/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8823 - loss: 0.2712 - val_accuracy: 0.7403 - val_loss: 0.7000\n",
            "Epoch 223/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8764 - loss: 0.2455 - val_accuracy: 0.7403 - val_loss: 0.7104\n",
            "Epoch 224/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8783 - loss: 0.2806 - val_accuracy: 0.7403 - val_loss: 0.7014\n",
            "Epoch 225/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8959 - loss: 0.2411 - val_accuracy: 0.7403 - val_loss: 0.7022\n",
            "Epoch 226/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8827 - loss: 0.2462 - val_accuracy: 0.7338 - val_loss: 0.7057\n",
            "Epoch 227/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8911 - loss: 0.2462 - val_accuracy: 0.7338 - val_loss: 0.7088\n",
            "Epoch 228/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8825 - loss: 0.2689 - val_accuracy: 0.7532 - val_loss: 0.7110\n",
            "Epoch 229/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9017 - loss: 0.2739 - val_accuracy: 0.7403 - val_loss: 0.7121\n",
            "Epoch 230/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9084 - loss: 0.2331 - val_accuracy: 0.7338 - val_loss: 0.7110\n",
            "Epoch 231/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8900 - loss: 0.2433 - val_accuracy: 0.7338 - val_loss: 0.7247\n",
            "Epoch 232/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8911 - loss: 0.2230 - val_accuracy: 0.7403 - val_loss: 0.7254\n",
            "Epoch 233/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8782 - loss: 0.2343 - val_accuracy: 0.7468 - val_loss: 0.7275\n",
            "Epoch 234/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9019 - loss: 0.2333 - val_accuracy: 0.7338 - val_loss: 0.7212\n",
            "Epoch 235/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8939 - loss: 0.2376 - val_accuracy: 0.7273 - val_loss: 0.7232\n",
            "Epoch 236/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8965 - loss: 0.2418 - val_accuracy: 0.7273 - val_loss: 0.7310\n",
            "Epoch 237/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8972 - loss: 0.2401 - val_accuracy: 0.7338 - val_loss: 0.7243\n",
            "Epoch 238/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8890 - loss: 0.2208 - val_accuracy: 0.7468 - val_loss: 0.7320\n",
            "Epoch 239/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8997 - loss: 0.2274 - val_accuracy: 0.7273 - val_loss: 0.7503\n",
            "Epoch 240/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8955 - loss: 0.2387 - val_accuracy: 0.7403 - val_loss: 0.7328\n",
            "Epoch 241/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8788 - loss: 0.2369 - val_accuracy: 0.7273 - val_loss: 0.7483\n",
            "Epoch 242/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8884 - loss: 0.2477 - val_accuracy: 0.7403 - val_loss: 0.7308\n",
            "Epoch 243/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8767 - loss: 0.2531 - val_accuracy: 0.7273 - val_loss: 0.7436\n",
            "Epoch 244/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8942 - loss: 0.2244 - val_accuracy: 0.7273 - val_loss: 0.7378\n",
            "Epoch 245/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8901 - loss: 0.2320 - val_accuracy: 0.7338 - val_loss: 0.7428\n",
            "Epoch 246/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8979 - loss: 0.2198 - val_accuracy: 0.7273 - val_loss: 0.7479\n",
            "Epoch 247/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9225 - loss: 0.2139 - val_accuracy: 0.7338 - val_loss: 0.7496\n",
            "Epoch 248/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8990 - loss: 0.2153 - val_accuracy: 0.7208 - val_loss: 0.7492\n",
            "Epoch 249/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8867 - loss: 0.2520 - val_accuracy: 0.7273 - val_loss: 0.7580\n",
            "Epoch 250/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9187 - loss: 0.2113 - val_accuracy: 0.7273 - val_loss: 0.7625\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9171 - loss: 0.2185 \n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7446 - loss: 0.6828 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 0.9087947607040405\n",
            "Testing Accuracy: 0.7272727489471436\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Precision: 0.6181818181818182\n",
            "Recall: 0.6181818181818182\n",
            "F1-Score: 0.6181818181818182\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step\n",
            "Predicted Class (0: Non-Diabetic, 1: Diabetic): 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}