{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303A52445/Generative-AI/blob/main/GAI_ASS_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import necessary libraries\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 2: Load the dataset (replace with the actual dataset path)\n",
        "# Make sure to replace 'path_to_your_dataset.csv' with the actual path to your dataset.\n",
        "dataset = pd.read_csv('/content/diabetes.csv')  # Load dataset\n",
        "\n",
        "# Step 3: Preprocess the data\n",
        "# Assuming 'Outcome' is the target variable (1 for diabetic, 0 for non-diabetic)\n",
        "X = dataset.drop(columns=['Outcome'])  # Features\n",
        "y = dataset['Outcome']  # Target variable\n",
        "\n",
        "# Normalize the features using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Split the data into training and testing sets (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 4: Build the ANN model\n",
        "model = Sequential()\n",
        "\n",
        "# Input layer and Hidden Layer 1 (10 neurons, tanh activation)\n",
        "model.add(Dense(10, input_dim=X_train.shape[1], activation='tanh'))\n",
        "\n",
        "# Hidden Layer 2 (15 neurons, tanh activation)\n",
        "model.add(Dense(15, activation='tanh'))\n",
        "\n",
        "# Hidden Layer 3 (20 neurons, tanh activation)\n",
        "model.add(Dense(20, activation='tanh'))\n",
        "\n",
        "# Hidden Layer 4 (10 neurons, tanh activation)\n",
        "model.add(Dense(10, activation='tanh'))\n",
        "\n",
        "# Hidden Layer 5 (5 neurons, tanh activation)\n",
        "model.add(Dense(5, activation='tanh'))\n",
        "\n",
        "# Output Layer (1 neuron for binary classification)\n",
        "model.add(Dense(1, activation='sigmoid'))  # Sigmoid activation for binary classification\n",
        "\n",
        "# Step 5: Compile the model with Adam optimizer, accuracy metric, and binary crossentropy loss function\n",
        "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 6: Train the model (epochs=250, batch_size=32)\n",
        "history = model.fit(X_train, y_train, epochs=250, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Step 7: Evaluate the model on the test data\n",
        "train_loss, train_accuracy = model.evaluate(X_train, y_train)\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "\n",
        "# Output training and testing accuracy\n",
        "print(f'Training Accuracy: {train_accuracy}')\n",
        "print(f'Testing Accuracy: {test_accuracy}')\n",
        "\n",
        "# Step 8: Save the model to a .h5 file\n",
        "model.save('diabetes_diagnosis_model.h5')\n",
        "\n",
        "# Step 9: (Evaluation) Calculate confusion matrix and classification metrics\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = (y_pred > 0.5).astype(int)  # Convert probabilities to binary class predictions\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Precision, Recall, and F1-Score\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1-Score: {f1}')\n",
        "\n",
        "# Plotting confusion matrix\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Non-Diabetic', 'Diabetic'], yticklabels=['Non-Diabetic', 'Diabetic'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "# Step 10: (Deployment) Load the saved model for future predictions\n",
        "from keras.models import load_model\n",
        "\n",
        "# Load the saved model\n",
        "loaded_model = load_model('diabetes_diagnosis_model.h5')\n",
        "\n",
        "# Example prediction on new data\n",
        "# Replace these placeholder values with actual values for a new patient\n",
        "# The number of values here should match the number of features (e.g., 10 values for 10 features)\n",
        "# Example prediction on new data\n",
        "# Replace these placeholder values with actual values for a new patient\n",
        "# The number of values here should match the number of features (e.g., 8 values for 8 features)\n",
        "\n",
        "new_data = [[5.1, 3.5, 1.4, 0.2, 6.0, 3.0, 4.5, 1.5]]  # Replace with actual new feature values (8 features)\n",
        "\n",
        "# Scale the new data using the same scaler used during training\n",
        "new_data = scaler.transform(new_data)\n",
        "\n",
        "# Make the prediction\n",
        "predicted_outcome = loaded_model.predict(new_data)\n",
        "\n",
        "# Convert the prediction to 0 or 1 (Diabetic or Non-Diabetic)\n",
        "predicted_class = (predicted_outcome > 0.5).astype(int)\n",
        "\n",
        "# Print the predicted class (0: Non-Diabetic, 1: Diabetic)\n",
        "print(f'Predicted Class (0: Non-Diabetic, 1: Diabetic): {predicted_class[0][0]}')"
      ],
      "metadata": {
        "id": "f8Lb8IN9rNKf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "92613c49-c3d1-4b41-ff34-91b963186465"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.6489 - loss: 0.6551 - val_accuracy: 0.6299 - val_loss: 0.6271\n",
            "Epoch 2/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7284 - loss: 0.5688 - val_accuracy: 0.6883 - val_loss: 0.5884\n",
            "Epoch 3/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7557 - loss: 0.5260 - val_accuracy: 0.7143 - val_loss: 0.5657\n",
            "Epoch 4/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7802 - loss: 0.4982 - val_accuracy: 0.7403 - val_loss: 0.5533\n",
            "Epoch 5/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8049 - loss: 0.4780 - val_accuracy: 0.7338 - val_loss: 0.5479\n",
            "Epoch 6/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7590 - loss: 0.4876 - val_accuracy: 0.7338 - val_loss: 0.5389\n",
            "Epoch 7/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7857 - loss: 0.4579 - val_accuracy: 0.7338 - val_loss: 0.5376\n",
            "Epoch 8/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7539 - loss: 0.4845 - val_accuracy: 0.7338 - val_loss: 0.5360\n",
            "Epoch 9/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7569 - loss: 0.4991 - val_accuracy: 0.7273 - val_loss: 0.5409\n",
            "Epoch 10/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7458 - loss: 0.5087 - val_accuracy: 0.7273 - val_loss: 0.5433\n",
            "Epoch 11/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7783 - loss: 0.4771 - val_accuracy: 0.7403 - val_loss: 0.5397\n",
            "Epoch 12/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7699 - loss: 0.4625 - val_accuracy: 0.7403 - val_loss: 0.5347\n",
            "Epoch 13/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7922 - loss: 0.4529 - val_accuracy: 0.7532 - val_loss: 0.5286\n",
            "Epoch 14/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8001 - loss: 0.4358 - val_accuracy: 0.7597 - val_loss: 0.5294\n",
            "Epoch 15/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7877 - loss: 0.4458 - val_accuracy: 0.7532 - val_loss: 0.5324\n",
            "Epoch 16/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7793 - loss: 0.4672 - val_accuracy: 0.7597 - val_loss: 0.5308\n",
            "Epoch 17/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7697 - loss: 0.4733 - val_accuracy: 0.7662 - val_loss: 0.5199\n",
            "Epoch 18/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8076 - loss: 0.4350 - val_accuracy: 0.7532 - val_loss: 0.5277\n",
            "Epoch 19/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7854 - loss: 0.4454 - val_accuracy: 0.7532 - val_loss: 0.5285\n",
            "Epoch 20/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7836 - loss: 0.4422 - val_accuracy: 0.7597 - val_loss: 0.5253\n",
            "Epoch 21/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7797 - loss: 0.4495 - val_accuracy: 0.7532 - val_loss: 0.5283\n",
            "Epoch 22/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7747 - loss: 0.4862 - val_accuracy: 0.7338 - val_loss: 0.5301\n",
            "Epoch 23/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7893 - loss: 0.4430 - val_accuracy: 0.7532 - val_loss: 0.5302\n",
            "Epoch 24/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7987 - loss: 0.4236 - val_accuracy: 0.7403 - val_loss: 0.5320\n",
            "Epoch 25/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7787 - loss: 0.4477 - val_accuracy: 0.7532 - val_loss: 0.5263\n",
            "Epoch 26/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7732 - loss: 0.4462 - val_accuracy: 0.7532 - val_loss: 0.5229\n",
            "Epoch 27/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7942 - loss: 0.4244 - val_accuracy: 0.7468 - val_loss: 0.5248\n",
            "Epoch 28/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7928 - loss: 0.4399 - val_accuracy: 0.7403 - val_loss: 0.5302\n",
            "Epoch 29/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7872 - loss: 0.4255 - val_accuracy: 0.7468 - val_loss: 0.5224\n",
            "Epoch 30/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7944 - loss: 0.4342 - val_accuracy: 0.7338 - val_loss: 0.5249\n",
            "Epoch 31/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7719 - loss: 0.4592 - val_accuracy: 0.7662 - val_loss: 0.5151\n",
            "Epoch 32/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7923 - loss: 0.4463 - val_accuracy: 0.7143 - val_loss: 0.5319\n",
            "Epoch 33/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8021 - loss: 0.4312 - val_accuracy: 0.7403 - val_loss: 0.5252\n",
            "Epoch 34/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7962 - loss: 0.4230 - val_accuracy: 0.7208 - val_loss: 0.5334\n",
            "Epoch 35/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8010 - loss: 0.4179 - val_accuracy: 0.7273 - val_loss: 0.5313\n",
            "Epoch 36/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8043 - loss: 0.4093 - val_accuracy: 0.7403 - val_loss: 0.5263\n",
            "Epoch 37/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7816 - loss: 0.4507 - val_accuracy: 0.7403 - val_loss: 0.5252\n",
            "Epoch 38/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7944 - loss: 0.4420 - val_accuracy: 0.7143 - val_loss: 0.5382\n",
            "Epoch 39/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7801 - loss: 0.4356 - val_accuracy: 0.7338 - val_loss: 0.5337\n",
            "Epoch 40/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7826 - loss: 0.4386 - val_accuracy: 0.7273 - val_loss: 0.5363\n",
            "Epoch 41/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7841 - loss: 0.4244 - val_accuracy: 0.7143 - val_loss: 0.5404\n",
            "Epoch 42/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8101 - loss: 0.4024 - val_accuracy: 0.7273 - val_loss: 0.5409\n",
            "Epoch 43/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7952 - loss: 0.4278 - val_accuracy: 0.7078 - val_loss: 0.5416\n",
            "Epoch 44/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7945 - loss: 0.4291 - val_accuracy: 0.7273 - val_loss: 0.5389\n",
            "Epoch 45/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7634 - loss: 0.4640 - val_accuracy: 0.7338 - val_loss: 0.5361\n",
            "Epoch 46/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8118 - loss: 0.4039 - val_accuracy: 0.7338 - val_loss: 0.5402\n",
            "Epoch 47/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8134 - loss: 0.3891 - val_accuracy: 0.7532 - val_loss: 0.5285\n",
            "Epoch 48/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7817 - loss: 0.4318 - val_accuracy: 0.7078 - val_loss: 0.5338\n",
            "Epoch 49/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7903 - loss: 0.4479 - val_accuracy: 0.7273 - val_loss: 0.5349\n",
            "Epoch 50/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8191 - loss: 0.3946 - val_accuracy: 0.7403 - val_loss: 0.5371\n",
            "Epoch 51/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7770 - loss: 0.4351 - val_accuracy: 0.7338 - val_loss: 0.5378\n",
            "Epoch 52/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8179 - loss: 0.4001 - val_accuracy: 0.7273 - val_loss: 0.5323\n",
            "Epoch 53/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7987 - loss: 0.4119 - val_accuracy: 0.7338 - val_loss: 0.5425\n",
            "Epoch 54/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8091 - loss: 0.4156 - val_accuracy: 0.7078 - val_loss: 0.5496\n",
            "Epoch 55/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7941 - loss: 0.4366 - val_accuracy: 0.7273 - val_loss: 0.5399\n",
            "Epoch 56/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8199 - loss: 0.4138 - val_accuracy: 0.7273 - val_loss: 0.5535\n",
            "Epoch 57/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7720 - loss: 0.4372 - val_accuracy: 0.7208 - val_loss: 0.5492\n",
            "Epoch 58/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8161 - loss: 0.4027 - val_accuracy: 0.7338 - val_loss: 0.5451\n",
            "Epoch 59/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7980 - loss: 0.4158 - val_accuracy: 0.7143 - val_loss: 0.5484\n",
            "Epoch 60/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7920 - loss: 0.4230 - val_accuracy: 0.7143 - val_loss: 0.5545\n",
            "Epoch 61/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7976 - loss: 0.3981 - val_accuracy: 0.7208 - val_loss: 0.5384\n",
            "Epoch 62/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8054 - loss: 0.4384 - val_accuracy: 0.7208 - val_loss: 0.5426\n",
            "Epoch 63/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7639 - loss: 0.4625 - val_accuracy: 0.7208 - val_loss: 0.5495\n",
            "Epoch 64/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7943 - loss: 0.3986 - val_accuracy: 0.7273 - val_loss: 0.5506\n",
            "Epoch 65/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8235 - loss: 0.3823 - val_accuracy: 0.7078 - val_loss: 0.5506\n",
            "Epoch 66/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7915 - loss: 0.4222 - val_accuracy: 0.7143 - val_loss: 0.5553\n",
            "Epoch 67/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8021 - loss: 0.4087 - val_accuracy: 0.7143 - val_loss: 0.5374\n",
            "Epoch 68/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7828 - loss: 0.4267 - val_accuracy: 0.7013 - val_loss: 0.5413\n",
            "Epoch 69/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8069 - loss: 0.4026 - val_accuracy: 0.7338 - val_loss: 0.5483\n",
            "Epoch 70/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7869 - loss: 0.4158 - val_accuracy: 0.7273 - val_loss: 0.5538\n",
            "Epoch 71/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8139 - loss: 0.3951 - val_accuracy: 0.7208 - val_loss: 0.5582\n",
            "Epoch 72/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8061 - loss: 0.4038 - val_accuracy: 0.7338 - val_loss: 0.5532\n",
            "Epoch 73/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8135 - loss: 0.3908 - val_accuracy: 0.7013 - val_loss: 0.5626\n",
            "Epoch 74/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8079 - loss: 0.4094 - val_accuracy: 0.7338 - val_loss: 0.5521\n",
            "Epoch 75/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8010 - loss: 0.4064 - val_accuracy: 0.7143 - val_loss: 0.5569\n",
            "Epoch 76/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8084 - loss: 0.3871 - val_accuracy: 0.7078 - val_loss: 0.5689\n",
            "Epoch 77/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7927 - loss: 0.4061 - val_accuracy: 0.7013 - val_loss: 0.5767\n",
            "Epoch 78/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8382 - loss: 0.3637 - val_accuracy: 0.7338 - val_loss: 0.5628\n",
            "Epoch 79/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8029 - loss: 0.4251 - val_accuracy: 0.7013 - val_loss: 0.5637\n",
            "Epoch 80/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8232 - loss: 0.3704 - val_accuracy: 0.7273 - val_loss: 0.5614\n",
            "Epoch 81/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8141 - loss: 0.3972 - val_accuracy: 0.7013 - val_loss: 0.5596\n",
            "Epoch 82/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7909 - loss: 0.4305 - val_accuracy: 0.7013 - val_loss: 0.5555\n",
            "Epoch 83/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7974 - loss: 0.3839 - val_accuracy: 0.7078 - val_loss: 0.5697\n",
            "Epoch 84/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8220 - loss: 0.3942 - val_accuracy: 0.7273 - val_loss: 0.5680\n",
            "Epoch 85/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8127 - loss: 0.3801 - val_accuracy: 0.7078 - val_loss: 0.5656\n",
            "Epoch 86/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8104 - loss: 0.3759 - val_accuracy: 0.7078 - val_loss: 0.5609\n",
            "Epoch 87/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8030 - loss: 0.4089 - val_accuracy: 0.7143 - val_loss: 0.5688\n",
            "Epoch 88/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8252 - loss: 0.3835 - val_accuracy: 0.7013 - val_loss: 0.5668\n",
            "Epoch 89/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8087 - loss: 0.3939 - val_accuracy: 0.7078 - val_loss: 0.5659\n",
            "Epoch 90/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8042 - loss: 0.3917 - val_accuracy: 0.7143 - val_loss: 0.5731\n",
            "Epoch 91/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8257 - loss: 0.3771 - val_accuracy: 0.7078 - val_loss: 0.5693\n",
            "Epoch 92/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8172 - loss: 0.3737 - val_accuracy: 0.6948 - val_loss: 0.5765\n",
            "Epoch 93/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7919 - loss: 0.3950 - val_accuracy: 0.7013 - val_loss: 0.5836\n",
            "Epoch 94/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7940 - loss: 0.3798 - val_accuracy: 0.7013 - val_loss: 0.5725\n",
            "Epoch 95/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7951 - loss: 0.4072 - val_accuracy: 0.7078 - val_loss: 0.5769\n",
            "Epoch 96/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8114 - loss: 0.3997 - val_accuracy: 0.6948 - val_loss: 0.5786\n",
            "Epoch 97/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8075 - loss: 0.3857 - val_accuracy: 0.6948 - val_loss: 0.5864\n",
            "Epoch 98/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8149 - loss: 0.3904 - val_accuracy: 0.7013 - val_loss: 0.5757\n",
            "Epoch 99/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8000 - loss: 0.3895 - val_accuracy: 0.7013 - val_loss: 0.5800\n",
            "Epoch 100/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8051 - loss: 0.3895 - val_accuracy: 0.7078 - val_loss: 0.5781\n",
            "Epoch 101/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8166 - loss: 0.3924 - val_accuracy: 0.6948 - val_loss: 0.5793\n",
            "Epoch 102/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8253 - loss: 0.3707 - val_accuracy: 0.7013 - val_loss: 0.5780\n",
            "Epoch 103/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8188 - loss: 0.3694 - val_accuracy: 0.6883 - val_loss: 0.5808\n",
            "Epoch 104/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8279 - loss: 0.3545 - val_accuracy: 0.7143 - val_loss: 0.5848\n",
            "Epoch 105/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8051 - loss: 0.3768 - val_accuracy: 0.6948 - val_loss: 0.5952\n",
            "Epoch 106/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8365 - loss: 0.3504 - val_accuracy: 0.7013 - val_loss: 0.5916\n",
            "Epoch 107/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7995 - loss: 0.3844 - val_accuracy: 0.7013 - val_loss: 0.5987\n",
            "Epoch 108/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7938 - loss: 0.4062 - val_accuracy: 0.7078 - val_loss: 0.5914\n",
            "Epoch 109/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8127 - loss: 0.3855 - val_accuracy: 0.6948 - val_loss: 0.5923\n",
            "Epoch 110/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8079 - loss: 0.3876 - val_accuracy: 0.7013 - val_loss: 0.5860\n",
            "Epoch 111/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8148 - loss: 0.3854 - val_accuracy: 0.7013 - val_loss: 0.5811\n",
            "Epoch 112/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8207 - loss: 0.3765 - val_accuracy: 0.6948 - val_loss: 0.5967\n",
            "Epoch 113/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8216 - loss: 0.3991 - val_accuracy: 0.7143 - val_loss: 0.5945\n",
            "Epoch 114/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8038 - loss: 0.4086 - val_accuracy: 0.7078 - val_loss: 0.5946\n",
            "Epoch 115/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7973 - loss: 0.3840 - val_accuracy: 0.7078 - val_loss: 0.6004\n",
            "Epoch 116/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8244 - loss: 0.3664 - val_accuracy: 0.7013 - val_loss: 0.6024\n",
            "Epoch 117/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7917 - loss: 0.3968 - val_accuracy: 0.7013 - val_loss: 0.5989\n",
            "Epoch 118/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8039 - loss: 0.4030 - val_accuracy: 0.7013 - val_loss: 0.5905\n",
            "Epoch 119/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8395 - loss: 0.3640 - val_accuracy: 0.7078 - val_loss: 0.6017\n",
            "Epoch 120/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8171 - loss: 0.3669 - val_accuracy: 0.7208 - val_loss: 0.6014\n",
            "Epoch 121/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8005 - loss: 0.3983 - val_accuracy: 0.7078 - val_loss: 0.6004\n",
            "Epoch 122/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8351 - loss: 0.3335 - val_accuracy: 0.7143 - val_loss: 0.6079\n",
            "Epoch 123/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8241 - loss: 0.3689 - val_accuracy: 0.7078 - val_loss: 0.5971\n",
            "Epoch 124/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8276 - loss: 0.3777 - val_accuracy: 0.7143 - val_loss: 0.6046\n",
            "Epoch 125/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8257 - loss: 0.3649 - val_accuracy: 0.7078 - val_loss: 0.6013\n",
            "Epoch 126/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8175 - loss: 0.3946 - val_accuracy: 0.7013 - val_loss: 0.6022\n",
            "Epoch 127/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8302 - loss: 0.3568 - val_accuracy: 0.6948 - val_loss: 0.5979\n",
            "Epoch 128/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8301 - loss: 0.3653 - val_accuracy: 0.6948 - val_loss: 0.6004\n",
            "Epoch 129/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8144 - loss: 0.3773 - val_accuracy: 0.7013 - val_loss: 0.6140\n",
            "Epoch 130/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8001 - loss: 0.3615 - val_accuracy: 0.7078 - val_loss: 0.6058\n",
            "Epoch 131/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7983 - loss: 0.3933 - val_accuracy: 0.7078 - val_loss: 0.6022\n",
            "Epoch 132/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8203 - loss: 0.3879 - val_accuracy: 0.6818 - val_loss: 0.6040\n",
            "Epoch 133/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8590 - loss: 0.3352 - val_accuracy: 0.6883 - val_loss: 0.6095\n",
            "Epoch 134/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8261 - loss: 0.3736 - val_accuracy: 0.7078 - val_loss: 0.6110\n",
            "Epoch 135/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8348 - loss: 0.3384 - val_accuracy: 0.7013 - val_loss: 0.6150\n",
            "Epoch 136/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8244 - loss: 0.3664 - val_accuracy: 0.6883 - val_loss: 0.6155\n",
            "Epoch 137/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8121 - loss: 0.3572 - val_accuracy: 0.6948 - val_loss: 0.6012\n",
            "Epoch 138/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8192 - loss: 0.3564 - val_accuracy: 0.6948 - val_loss: 0.6032\n",
            "Epoch 139/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8354 - loss: 0.3700 - val_accuracy: 0.6818 - val_loss: 0.6139\n",
            "Epoch 140/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8399 - loss: 0.3450 - val_accuracy: 0.6948 - val_loss: 0.6143\n",
            "Epoch 141/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8380 - loss: 0.3440 - val_accuracy: 0.7013 - val_loss: 0.6072\n",
            "Epoch 142/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8149 - loss: 0.3834 - val_accuracy: 0.6818 - val_loss: 0.6163\n",
            "Epoch 143/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8361 - loss: 0.3448 - val_accuracy: 0.7013 - val_loss: 0.6124\n",
            "Epoch 144/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8427 - loss: 0.3379 - val_accuracy: 0.6883 - val_loss: 0.6215\n",
            "Epoch 145/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8571 - loss: 0.3311 - val_accuracy: 0.6948 - val_loss: 0.6115\n",
            "Epoch 146/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8280 - loss: 0.3542 - val_accuracy: 0.7078 - val_loss: 0.6140\n",
            "Epoch 147/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8152 - loss: 0.3905 - val_accuracy: 0.6948 - val_loss: 0.6220\n",
            "Epoch 148/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8155 - loss: 0.3635 - val_accuracy: 0.7143 - val_loss: 0.6173\n",
            "Epoch 149/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8516 - loss: 0.3602 - val_accuracy: 0.6948 - val_loss: 0.6185\n",
            "Epoch 150/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8224 - loss: 0.3666 - val_accuracy: 0.6948 - val_loss: 0.6136\n",
            "Epoch 151/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8303 - loss: 0.3531 - val_accuracy: 0.7078 - val_loss: 0.6173\n",
            "Epoch 152/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8469 - loss: 0.3428 - val_accuracy: 0.7078 - val_loss: 0.6258\n",
            "Epoch 153/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8448 - loss: 0.3459 - val_accuracy: 0.6948 - val_loss: 0.6217\n",
            "Epoch 154/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8454 - loss: 0.3557 - val_accuracy: 0.7208 - val_loss: 0.6167\n",
            "Epoch 155/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8322 - loss: 0.3528 - val_accuracy: 0.7078 - val_loss: 0.6154\n",
            "Epoch 156/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8472 - loss: 0.3325 - val_accuracy: 0.7078 - val_loss: 0.6136\n",
            "Epoch 157/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8391 - loss: 0.3651 - val_accuracy: 0.7013 - val_loss: 0.6194\n",
            "Epoch 158/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8470 - loss: 0.3335 - val_accuracy: 0.7013 - val_loss: 0.6231\n",
            "Epoch 159/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8120 - loss: 0.3887 - val_accuracy: 0.6948 - val_loss: 0.6228\n",
            "Epoch 160/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8540 - loss: 0.3464 - val_accuracy: 0.7078 - val_loss: 0.6163\n",
            "Epoch 161/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8482 - loss: 0.3311 - val_accuracy: 0.7078 - val_loss: 0.6204\n",
            "Epoch 162/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8365 - loss: 0.3440 - val_accuracy: 0.7013 - val_loss: 0.6257\n",
            "Epoch 163/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8622 - loss: 0.3354 - val_accuracy: 0.7208 - val_loss: 0.6198\n",
            "Epoch 164/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8535 - loss: 0.3230 - val_accuracy: 0.7013 - val_loss: 0.6230\n",
            "Epoch 165/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8132 - loss: 0.3801 - val_accuracy: 0.7078 - val_loss: 0.6225\n",
            "Epoch 166/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8743 - loss: 0.3010 - val_accuracy: 0.7143 - val_loss: 0.6218\n",
            "Epoch 167/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8473 - loss: 0.3245 - val_accuracy: 0.6818 - val_loss: 0.6394\n",
            "Epoch 168/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8290 - loss: 0.3555 - val_accuracy: 0.7078 - val_loss: 0.6336\n",
            "Epoch 169/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8237 - loss: 0.3594 - val_accuracy: 0.7078 - val_loss: 0.6299\n",
            "Epoch 170/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8886 - loss: 0.2922 - val_accuracy: 0.7143 - val_loss: 0.6347\n",
            "Epoch 171/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8543 - loss: 0.3466 - val_accuracy: 0.6948 - val_loss: 0.6329\n",
            "Epoch 172/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8572 - loss: 0.3071 - val_accuracy: 0.7143 - val_loss: 0.6267\n",
            "Epoch 173/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8561 - loss: 0.3212 - val_accuracy: 0.6948 - val_loss: 0.6444\n",
            "Epoch 174/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8530 - loss: 0.3257 - val_accuracy: 0.7078 - val_loss: 0.6355\n",
            "Epoch 175/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8591 - loss: 0.3051 - val_accuracy: 0.7013 - val_loss: 0.6445\n",
            "Epoch 176/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8386 - loss: 0.3451 - val_accuracy: 0.7078 - val_loss: 0.6457\n",
            "Epoch 177/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8430 - loss: 0.3478 - val_accuracy: 0.7078 - val_loss: 0.6438\n",
            "Epoch 178/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8510 - loss: 0.3279 - val_accuracy: 0.7013 - val_loss: 0.6444\n",
            "Epoch 179/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8626 - loss: 0.3287 - val_accuracy: 0.7013 - val_loss: 0.6428\n",
            "Epoch 180/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8657 - loss: 0.3309 - val_accuracy: 0.7143 - val_loss: 0.6393\n",
            "Epoch 181/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8600 - loss: 0.3198 - val_accuracy: 0.7143 - val_loss: 0.6428\n",
            "Epoch 182/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8387 - loss: 0.3397 - val_accuracy: 0.7143 - val_loss: 0.6289\n",
            "Epoch 183/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8311 - loss: 0.3528 - val_accuracy: 0.6948 - val_loss: 0.6449\n",
            "Epoch 184/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8373 - loss: 0.3392 - val_accuracy: 0.7013 - val_loss: 0.6446\n",
            "Epoch 185/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8458 - loss: 0.3258 - val_accuracy: 0.7013 - val_loss: 0.6485\n",
            "Epoch 186/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8436 - loss: 0.3530 - val_accuracy: 0.6948 - val_loss: 0.6545\n",
            "Epoch 187/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8452 - loss: 0.3578 - val_accuracy: 0.6883 - val_loss: 0.6599\n",
            "Epoch 188/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8634 - loss: 0.3102 - val_accuracy: 0.7078 - val_loss: 0.6461\n",
            "Epoch 189/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8502 - loss: 0.3233 - val_accuracy: 0.7078 - val_loss: 0.6595\n",
            "Epoch 190/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8517 - loss: 0.3470 - val_accuracy: 0.7078 - val_loss: 0.6495\n",
            "Epoch 191/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8715 - loss: 0.2910 - val_accuracy: 0.6948 - val_loss: 0.6590\n",
            "Epoch 192/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8762 - loss: 0.2850 - val_accuracy: 0.7013 - val_loss: 0.6570\n",
            "Epoch 193/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8850 - loss: 0.2800 - val_accuracy: 0.7078 - val_loss: 0.6617\n",
            "Epoch 194/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8403 - loss: 0.3237 - val_accuracy: 0.7143 - val_loss: 0.6546\n",
            "Epoch 195/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8510 - loss: 0.3204 - val_accuracy: 0.7208 - val_loss: 0.6635\n",
            "Epoch 196/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8405 - loss: 0.3413 - val_accuracy: 0.7143 - val_loss: 0.6666\n",
            "Epoch 197/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8457 - loss: 0.3338 - val_accuracy: 0.7078 - val_loss: 0.6550\n",
            "Epoch 198/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8465 - loss: 0.3140 - val_accuracy: 0.7078 - val_loss: 0.6573\n",
            "Epoch 199/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8601 - loss: 0.3349 - val_accuracy: 0.7078 - val_loss: 0.6622\n",
            "Epoch 200/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8549 - loss: 0.3169 - val_accuracy: 0.7143 - val_loss: 0.6615\n",
            "Epoch 201/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8472 - loss: 0.3149 - val_accuracy: 0.7078 - val_loss: 0.6639\n",
            "Epoch 202/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8698 - loss: 0.2935 - val_accuracy: 0.7208 - val_loss: 0.6642\n",
            "Epoch 203/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8823 - loss: 0.2786 - val_accuracy: 0.7078 - val_loss: 0.6743\n",
            "Epoch 204/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8745 - loss: 0.2961 - val_accuracy: 0.7143 - val_loss: 0.6667\n",
            "Epoch 205/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8653 - loss: 0.3003 - val_accuracy: 0.7208 - val_loss: 0.6665\n",
            "Epoch 206/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8469 - loss: 0.3172 - val_accuracy: 0.7143 - val_loss: 0.6660\n",
            "Epoch 207/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8695 - loss: 0.2862 - val_accuracy: 0.7078 - val_loss: 0.6764\n",
            "Epoch 208/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8689 - loss: 0.3060 - val_accuracy: 0.7208 - val_loss: 0.6719\n",
            "Epoch 209/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8658 - loss: 0.3024 - val_accuracy: 0.7208 - val_loss: 0.6756\n",
            "Epoch 210/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8546 - loss: 0.2962 - val_accuracy: 0.7208 - val_loss: 0.6706\n",
            "Epoch 211/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8299 - loss: 0.3310 - val_accuracy: 0.7208 - val_loss: 0.6778\n",
            "Epoch 212/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8554 - loss: 0.3218 - val_accuracy: 0.7273 - val_loss: 0.6751\n",
            "Epoch 213/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8335 - loss: 0.3368 - val_accuracy: 0.7273 - val_loss: 0.6741\n",
            "Epoch 214/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8447 - loss: 0.3245 - val_accuracy: 0.7208 - val_loss: 0.6730\n",
            "Epoch 215/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8532 - loss: 0.3065 - val_accuracy: 0.7208 - val_loss: 0.6823\n",
            "Epoch 216/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8926 - loss: 0.2779 - val_accuracy: 0.7143 - val_loss: 0.6867\n",
            "Epoch 217/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8922 - loss: 0.2791 - val_accuracy: 0.7208 - val_loss: 0.6732\n",
            "Epoch 218/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8574 - loss: 0.3199 - val_accuracy: 0.7208 - val_loss: 0.6808\n",
            "Epoch 219/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8733 - loss: 0.2744 - val_accuracy: 0.7143 - val_loss: 0.6730\n",
            "Epoch 220/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8369 - loss: 0.3107 - val_accuracy: 0.6948 - val_loss: 0.6848\n",
            "Epoch 221/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8894 - loss: 0.2729 - val_accuracy: 0.7078 - val_loss: 0.6818\n",
            "Epoch 222/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8573 - loss: 0.3106 - val_accuracy: 0.7078 - val_loss: 0.6901\n",
            "Epoch 223/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8420 - loss: 0.3366 - val_accuracy: 0.7208 - val_loss: 0.6805\n",
            "Epoch 224/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8892 - loss: 0.2740 - val_accuracy: 0.7078 - val_loss: 0.6890\n",
            "Epoch 225/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8793 - loss: 0.2769 - val_accuracy: 0.7273 - val_loss: 0.6902\n",
            "Epoch 226/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8601 - loss: 0.2973 - val_accuracy: 0.7078 - val_loss: 0.6833\n",
            "Epoch 227/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8630 - loss: 0.2821 - val_accuracy: 0.7143 - val_loss: 0.6951\n",
            "Epoch 228/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8653 - loss: 0.2913 - val_accuracy: 0.7273 - val_loss: 0.6835\n",
            "Epoch 229/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8535 - loss: 0.2940 - val_accuracy: 0.7208 - val_loss: 0.6858\n",
            "Epoch 230/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8878 - loss: 0.2870 - val_accuracy: 0.7013 - val_loss: 0.7004\n",
            "Epoch 231/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8770 - loss: 0.2834 - val_accuracy: 0.7013 - val_loss: 0.6930\n",
            "Epoch 232/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8848 - loss: 0.2906 - val_accuracy: 0.7143 - val_loss: 0.6952\n",
            "Epoch 233/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8851 - loss: 0.2628 - val_accuracy: 0.7078 - val_loss: 0.7002\n",
            "Epoch 234/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8851 - loss: 0.2647 - val_accuracy: 0.7208 - val_loss: 0.6998\n",
            "Epoch 235/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8695 - loss: 0.2850 - val_accuracy: 0.6948 - val_loss: 0.7038\n",
            "Epoch 236/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8879 - loss: 0.2466 - val_accuracy: 0.7078 - val_loss: 0.6994\n",
            "Epoch 237/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8579 - loss: 0.2921 - val_accuracy: 0.7143 - val_loss: 0.7178\n",
            "Epoch 238/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8633 - loss: 0.2943 - val_accuracy: 0.7013 - val_loss: 0.6972\n",
            "Epoch 239/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8721 - loss: 0.2862 - val_accuracy: 0.7143 - val_loss: 0.7000\n",
            "Epoch 240/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8756 - loss: 0.2810 - val_accuracy: 0.7078 - val_loss: 0.7083\n",
            "Epoch 241/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8927 - loss: 0.2590 - val_accuracy: 0.7078 - val_loss: 0.7066\n",
            "Epoch 242/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8757 - loss: 0.2601 - val_accuracy: 0.7078 - val_loss: 0.7008\n",
            "Epoch 243/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8916 - loss: 0.2858 - val_accuracy: 0.7078 - val_loss: 0.7095\n",
            "Epoch 244/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8553 - loss: 0.3221 - val_accuracy: 0.7013 - val_loss: 0.7015\n",
            "Epoch 245/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8905 - loss: 0.2595 - val_accuracy: 0.7143 - val_loss: 0.7067\n",
            "Epoch 246/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8645 - loss: 0.2907 - val_accuracy: 0.7143 - val_loss: 0.7062\n",
            "Epoch 247/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8841 - loss: 0.2553 - val_accuracy: 0.7143 - val_loss: 0.7100\n",
            "Epoch 248/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9132 - loss: 0.2461 - val_accuracy: 0.6948 - val_loss: 0.7231\n",
            "Epoch 249/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8947 - loss: 0.2603 - val_accuracy: 0.7208 - val_loss: 0.7155\n",
            "Epoch 250/250\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8791 - loss: 0.2881 - val_accuracy: 0.7143 - val_loss: 0.7041\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8915 - loss: 0.2856 \n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7155 - loss: 0.6832 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 0.8892508149147034\n",
            "Testing Accuracy: 0.7142857313156128\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Precision: 0.6\n",
            "Recall: 0.6\n",
            "F1-Score: 0.6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Class (0: Non-Diabetic, 1: Diabetic): 0\n"
          ]
        }
      ]
    }
  ]
}